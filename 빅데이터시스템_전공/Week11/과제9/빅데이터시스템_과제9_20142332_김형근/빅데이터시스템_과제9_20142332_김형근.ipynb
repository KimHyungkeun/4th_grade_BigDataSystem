{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+----------+------+-------------------+-----------+------+\n",
      "| id|firstName|middleName|  lastName|gender|          birthDate|        ssn|salary|\n",
      "+---+---------+----------+----------+------+-------------------+-----------+------+\n",
      "|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 13:30:00|981-43-9345| 56172|\n",
      "|  2|       An|     Amira|    Cowper|     F|1992-02-08 14:00:00|978-97-8086| 40203|\n",
      "|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 13:00:00|957-57-8246| 53417|\n",
      "|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 13:00:00|963-39-4885| 94727|\n",
      "|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 14:00:00|964-49-8051| 79908|\n",
      "+---+---------+----------+----------+------+-------------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF = spark.read.parquet(\"D:/김형근4학년2학기/빅데이터시스템(전공)/11주차/과제9/people-10m.parquet\")\n",
    "peopleDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['firstName', 'middleName', 'lastName']\n",
      "+---------+----------+----------+\n",
      "|firstName|middleName|  lastName|\n",
      "+---------+----------+----------+\n",
      "|   Pennie|     Carry|Hirschmann|\n",
      "+---------+----------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+----------+-----+\n",
      "|middleName|count|\n",
      "+----------+-----+\n",
      "|     Tegan| 1309|\n",
      "|      Reta| 1277|\n",
      "|  Julianne| 1260|\n",
      "|     Sandi| 1233|\n",
      "|   Susanna| 1255|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_lst = [c for c in peopleDF.columns if 'Name' in c]\n",
    "print(name_lst)\n",
    "nameDF = peopleDF[name_lst]\n",
    "nameDF.show(1)\n",
    "\n",
    "nameDF.groupBy('middleName').count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5113\n",
      "+---------+\n",
      "|firstName|\n",
      "+---------+\n",
      "|    Zulma|\n",
      "|   Zulema|\n",
      "|     Zula|\n",
      "|  Zoraida|\n",
      "|     Zora|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstName = peopleDF.select('firstName').distinct()\n",
    "print(firstName.count())\n",
    "sortingDF = firstName.orderBy('firstName', ascending=False)\n",
    "sortingDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+\n",
      "|birthYear|firstName|count|\n",
      "+---------+---------+-----+\n",
      "|     1952|  Dorothy|   21|\n",
      "|     1952|    Donna|   24|\n",
      "|     1953|    Donna|   37|\n",
      "|     1953|  Dorothy|   38|\n",
      "|     1954|  Dorothy|   29|\n",
      "+---------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, col\n",
    "dordonDF = peopleDF.\\\n",
    "            select(year('birthDate').alias(\"birthYear\"), \"firstName\").\\\n",
    "            filter((col(\"firstName\")=='Donna') | (col(\"firstName\")=='Dorothy')).\\\n",
    "            filter(\"gender == 'F'\").\\\n",
    "            groupBy('birthYear','firstName').\\\n",
    "            count().orderBy('birthYear').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dordonDF = peopleDF.\\\n",
    "            select(year('birthDate').alias(\"birthYear\"), \"firstName\").\\\n",
    "            filter((col(\"firstName\")=='Donna') | (col(\"firstName\")=='Dorothy')).\\\n",
    "            filter(\"gender == 'F'\").\\\n",
    "            filter(year('birthDate') >= \"1990\").\\\n",
    "            groupBy('birthYear','firstName').\\\n",
    "            count().orderBy('birthYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[birthYear: int, firstName: string, count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dordonDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesA = [('tom', 70), ('bob', 100), ('sam', 60), ('lee', 85), ('jun', 75)]\n",
    "valuesB = [('tom', 55), ('sam', 88), ('kim', 90), ('jun', 67), ('choi', 95)]\n",
    "mathS_df = spark.createDataFrame(valuesA, ['name', 'score'])\n",
    "englishS_df = spark.createDataFrame(valuesB, ['name', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|score|\n",
      "+----+-----+\n",
      "| tom|   70|\n",
      "| bob|  100|\n",
      "| sam|   60|\n",
      "| lee|   85|\n",
      "| jun|   75|\n",
      "+----+-----+\n",
      "\n",
      "+----+-----+\n",
      "|name|score|\n",
      "+----+-----+\n",
      "| tom|   55|\n",
      "| sam|   88|\n",
      "| kim|   90|\n",
      "| jun|   67|\n",
      "|choi|   95|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mathS_df.show()\n",
    "englishS_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+-------------+\n",
      "|name|math score|name|english score|\n",
      "+----+----------+----+-------------+\n",
      "| jun|        75| jun|           67|\n",
      "| tom|        70| tom|           55|\n",
      "| sam|        60| sam|           88|\n",
      "+----+----------+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mathS_df = mathS_df.withColumnRenamed('score', 'math score')\n",
    "englishS_df = englishS_df.withColumnRenamed('score', 'english score')\n",
    "\n",
    "join1 = mathS_df.join(englishS_df, mathS_df.name == englishS_df.name)\n",
    "join1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+-------------+\n",
      "|name|math score|name|english score|\n",
      "+----+----------+----+-------------+\n",
      "|null|      null|choi|           95|\n",
      "|null|      null| kim|           90|\n",
      "+----+----------+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mathS_df = mathS_df.withColumnRenamed('score', 'math score')\n",
    "englishS_df = englishS_df.withColumnRenamed('score', 'english score')\n",
    "\n",
    "join2 = mathS_df.join(englishS_df, mathS_df.name == englishS_df.name, how='right')\\\n",
    "                .filter(mathS_df.name.isNull())\n",
    "join2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|firstName|total|\n",
      "+---------+-----+\n",
      "|  Marcelo| 4197|\n",
      "| Reynaldo| 4193|\n",
      "|  Jeffrey| 4177|\n",
      "|   Sammie| 4170|\n",
      "|     Troy| 4167|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top10MaleFirstNameDF = peopleDF.\\\n",
    "                        select(\"firstName\").\\\n",
    "                        filter(\"gender = 'M'\").\\\n",
    "                        groupBy(\"firstName\").\\\n",
    "                        agg(count(col('firstName')).alias('total')).\\\n",
    "                        orderBy(desc('total')).\\\n",
    "                        limit(10)\n",
    "\n",
    "top10MaleFirstNameDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[firstName: string, total: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10MaleFirstNameDF.createOrReplaceTempView(\"top10MaleFirstName\")\n",
    "resultsDF = spark.sql(\"select * from top10MaleFirstName order by FirstName\")\n",
    "display(resultsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
