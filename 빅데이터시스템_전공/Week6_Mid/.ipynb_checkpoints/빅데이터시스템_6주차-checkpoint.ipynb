{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262\n",
      "[('Amber', 22), ('Alfred', 23), ('Skye', 4), ('Albert', 12), ('Amber', 9)]\n"
     ]
    }
   ],
   "source": [
    "data = sc.parallelize(\n",
    "[('Amber',22),('Alfred',23),('Skye',4),('Albert',12),('Amber',9)])\n",
    "print(data)\n",
    "print(data.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4017094072211322, -0.37429654119281647, 1.6035863690545253, 0.3766149173754111, 0.11793385017271235, 0.5558832314951401, -1.2926690929328197, -0.6251785868900387, 0.30749640219724644, -1.0573510480576656]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rData = [np.random.randn() for _ in range(10)]\n",
    "print(rData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      " ParallelCollectionRDD[2] at readRDDFromFile at PythonRDD.scala:262\n",
      "all data\n",
      " [-0.4017094072211322, -0.37429654119281647, 1.6035863690545253, 0.3766149173754111, 0.11793385017271235, 0.5558832314951401, -1.2926690929328197, -0.6251785868900387, 0.30749640219724644, -1.0573510480576656]\n",
      "the first 5\n",
      " [-0.4017094072211322, -0.37429654119281647, 1.6035863690545253, 0.3766149173754111, 0.11793385017271235]\n"
     ]
    }
   ],
   "source": [
    "data = sc.parallelize(rData)\n",
    "print(\"data\\n\", data) #해당 context의 정보 표기\n",
    "print(\"all data\\n\", data.collect())\n",
    "print(\"the first 5\\n\", data.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('park', 43), ('kim', 25)]\n"
     ]
    }
   ],
   "source": [
    "data = sc.parallelize([(\"park\",43),(\"kim\",25)])\n",
    "print(data.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ROMEO AND JULIET',\n",
       " '',\n",
       " '',\n",
       " 'ACT I',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'SCENE I\\tVerona. A public place.',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile(\"./test1.txt\")\n",
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'a', 'c']\n",
      "ParallelCollectionRDD[9] at readRDDFromFile at PythonRDD.scala:262\n"
     ]
    }
   ],
   "source": [
    "# map \n",
    "x = sc.parallelize([\"b\",\"a\",\"c\"])\n",
    "print(x.collect())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 1), ('a', 1), ('c', 1)]\n",
      "PythonRDD[10] at collect at <ipython-input-10-cfaae7e231aa>:2\n"
     ]
    }
   ],
   "source": [
    "y = x.map(lambda z : (z,1))\n",
    "print(y.collect())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "x = sc.parallelize([1,2,3])\n",
    "y = x.filter(lambda x : x%2 == 1) # 홀수만 골라내기\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 100, 42, 2, 200, 42, 3, 300, 42]\n"
     ]
    }
   ],
   "source": [
    "# flatmap\n",
    "x = sc.parallelize([1,2,3])\n",
    "y = x.flatMap(lambda x : (x, x * 100, 42))\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[(1, 100, 42), (2, 200, 42), (3, 300, 42)]\n"
     ]
    }
   ],
   "source": [
    "# map과 비교\n",
    "x = sc.parallelize([1,2,3])\n",
    "y = x.map(lambda x : (x, x * 100, 42))\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('J', ['John', 'James']), ('F', ['Fred']), ('A', ['Anna'])]\n"
     ]
    }
   ],
   "source": [
    "# groupBy에서는 함수 또는 키를 지정해야함, groupByKey라는 것도 있는데 이거는 key를 이미 알고 있을때\n",
    "x = sc.parallelize(['John', 'Fred', 'Anna', 'James'])\n",
    "y = x.groupBy(lambda w : w[0]) # key 값을 결정해주면, key값에 따라 그룹이 나뉨\n",
    "print([(k, list(v)) for (k,v) in y.collect()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[23] at collect at <ipython-input-15-2f667b2a4988>:3\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('J', <pyspark.resultiterable.ResultIterable at 0x257fb86dcd0>),\n",
       " ('F', <pyspark.resultiterable.ResultIterable at 0x257fb96dca0>),\n",
       " ('A', <pyspark.resultiterable.ResultIterable at 0x257fb96df70>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in y.collect()] # list형태로 지정해서 출력해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
